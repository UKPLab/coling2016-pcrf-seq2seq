# PCRF-Seq2Seq



Please use the following citation:

```
@inproceedings{	TUD-CS-2016450,
	author = {Carsten Schnober and Steffen Eger and Erik-Lân Do Dinh and Iryna Gurevych},
	title = {Still not there? Comparing Traditional Sequence-to-Sequence Models to
Encoder-Decoder Neural Networks on Monotone String Translation Tasks},
	month = dec,
	year = {2016},
	booktitle = {Proceedings of the 26th International Conference on Computational
Linguistics (COLING)},
	pages = {(to appear)},
	location = {Osaka, Japan},
	language = {English},
	pubkey = {TUD-CS-2016-1450},
	research_area = {Ubiquitous Knowledge Processing, UKP-DIPF},
	research_sub_area = {UKP_reviewed, UKP_a_DLinNLP},
	abstract = {We analyze the performance of encoder-decoder neural models and compare
them with well-known established methods. The latter represent different
classes of traditional approaches that are applied to the monotone
sequence-to-sequence tasks OCR post-correction, spelling correction,
grapheme-to-phoneme conversion, and lemmatization.
Such tasks are of practical relevance for various higher-level research
fields including \textit{digital humanities}, automatic text correction,
and speech recognition. 
We investigate how well generic deep-learning approaches adapt to these
tasks, and how they perform in comparison with established and more
specialized methods, including our own adaptation of pruned CRFs. },
}
```

> **Abstract:** We analyze the performance of encoder-decoder neural models and compare them with well-known established methods. The latter represent different classes of traditional approaches that are applied to the monotone sequence-to-sequence tasks OCR post-correction, spelling correction, grapheme-to-phoneme conversion, and lemmatization.
Such tasks are of practical relevance for various higher-level research fields including \textit{digital humanities}, automatic text correction, and speech recognition. 
We investigate how well generic deep-learning approaches adapt to these tasks, and how they perform in comparison with established and more specialized methods, including our own adaptation of pruned CRFs. 


Contact person: 
  * Carsten Schnober, schnober@ukp.informatik.tu-darmstadt.de
  * Steffen Eger, eger@ukp.informatik.tu-darmstadt.de
  * Erik-Lân Do Dinh, dodinh@ukp.informatik.tu-darmstadt.de

http://www.ukp.tu-darmstadt.de/

http://www.tu-darmstadt.de/


Don't hesitate to send us an e-mail or report an issue, if something is broken (and it shouldn't be) or if you have further questions.

> This repository contains experimental software and is published for the sole purpose of giving additional background details on the respective publication. 

## Project structure
**(change this as needed!)**

* `folder/a` -- this folder contains xxx
* `folder/b` -- interesting files here
* ...
* `data/xxx` -- my amazing data

## Requirements
**(change this as needed!)**

* Java x.x and higher
* Maven
* 64-bit Linux versions
* Windows x
* XX GB RAM

## Installation
**(change this as needed!)**

* Step 1

```
$nice_command

$some_script.sh
```

* Step 2

Do something and something

* ...
* Step n


## Running the experiments
**(change this as needed!)**

```
$cd bla/bla/bla
$some_cool_commands_here
```

### Expected results
**(change this as needed!)**

After running the experiments, you should expect the following results:

(Feel free to describe your expected results here...)

### Parameter description
**(change this as needed!)**

* `x, --xxxx`
  * This parameter does something nice
...
* `z, --zzzz`
  * This parameter does something even nicer
  
